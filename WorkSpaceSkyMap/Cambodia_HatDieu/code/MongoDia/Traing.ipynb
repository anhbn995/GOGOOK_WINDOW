{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_and_mask_train(fp_mask, nodata_value=0):\n",
    "    src = rasterio.open(fp_mask)\n",
    "    mask = src.read()[0].flatten()\n",
    "    index_nodata = np.where(mask == nodata_value)\n",
    "    mask_train = np.delete(mask, index_nodata)\n",
    "    return mask_train, index_nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_flatten_train(fp_img, list_number_band, index_nodata, name_atrr):\n",
    "    src = rasterio.open(fp_img)\n",
    "    # return to img train\n",
    "    list_band_have = list(range(1,src.count+1))\n",
    "    dfObj = pd.DataFrame()\n",
    "    if set(list_number_band).issubset(list_band_have):\n",
    "        img = src.read(list_number_band)\n",
    "        i = 0\n",
    "        for band in img:\n",
    "            band = band.flatten()\n",
    "            band = np.delete(band, index_nodata)\n",
    "            name_band = f\"band {list_number_band[i]}_{name_atrr}\"\n",
    "            dfObj[name_band] = band\n",
    "            i+=1\n",
    "        return dfObj\n",
    "    else:\n",
    "        miss = np.setdiff1d(list_number_band, list_band_have)\n",
    "        print(\"*\"*15, \"ERROR\", \"*\"*15)\n",
    "        print(f\"Image dont have band : {miss.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_image_by_time(dir_img):\n",
    "    list_name_file = os.listdir(dir_img)\n",
    "    print(list_name_file)\n",
    "    list_time = []\n",
    "    for name in list_name_file:\n",
    "        list_time.append(name[17:25])\n",
    "    list_time.sort(key=lambda date: datetime.strptime(date, '%Y%m%d'))\n",
    "    return list_time[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_train(list_fp_img, list_name_file_sort, list_number_band, index_nodata,fp_csv):\n",
    "    fp_img_first = [s for s in list_fp_img if list_name_file_sort[0] in s][0]\n",
    "    df = get_df_flatten_train(fp_img_first, list_number_band, index_nodata, list_name_file_sort[0])\n",
    "    print(df.shape,\"a\")\n",
    "    for name_file_sort in list_name_file_sort[1:]:\n",
    "        fp_img = [s for s in list_fp_img if name_file_sort in s][0]\n",
    "        df1 = get_df_flatten_train(fp_img, list_number_band, index_nodata, name_file_sort)\n",
    "        df = pd.concat([df, df1], axis=1)\n",
    "        print(df.shape)\n",
    "    df.to_csv(fp_csv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dao_ngay_df(df, list_colums):\n",
    "    df_get = pd.concat([df.pop(x) for x in list_colums], axis=1)\n",
    "    return pd.concat([df,df_get ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_seris(fp_csv):\n",
    "    datasets = pd.read_csv(fp_csv)\n",
    "    list_name_band = datasets.columns.to_list()\n",
    "    tmp_df = datasets.copy()\n",
    "    for i in range(8):\n",
    "        list_7_band = list_name_band[0:7]\n",
    "        tmp_df = dao_ngay_df(tmp_df, list_7_band)\n",
    "        tmp_df.columns = list_name_band\n",
    "        datasets = pd.concat([datasets, tmp_df])\n",
    "    print(datasets.shape)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training DENSE NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  7 16:15:55 2022\n",
    "\n",
    "@author: SkyMap\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Dense, BatchNormalization, ReLU\n",
    "    \n",
    "import rasterio\n",
    "from sklearn import datasets\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input, label, classes=7, epochs=100, batch_size=100, shuffle=True, model_path='model.h5'):\n",
    "    assert classes>=2, 'number classese must be more than 1'\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 63))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    if classes==2:\n",
    "        model.add(Dense(2, activation = 'sigmoid'))\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        model.add(Dense(classes, activation = 'softmax'))\n",
    "        loss='categorical_crossentropy'\n",
    "\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(input, label, epochs=epochs, batch_size=batch_size, shuffle=shuffle)\n",
    "    scores = model.evaluate(input, label)\n",
    "    print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_train(df):\n",
    "    datasets = df.iloc[:, 2:]\n",
    "    print(datasets.shape)\n",
    "    X = datasets.iloc[:, :-1]\n",
    "    Y = datasets.iloc[:, -1]\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    encoded_Y = encoder.transform(Y)\n",
    "    Y = np_utils.to_categorical(encoded_Y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LC08_L2SP_131027_20210203_20210303_02_T1_0.tif', 'LC08_L2SP_131027_20210219_20210302_02_T1_0.tif', 'LC08_L2SP_131027_20210323_20210402_02_T1_0.tif', 'LC08_L2SP_131027_20210408_20210416_02_T1_0.tif', 'LC08_L2SP_131027_20210627_20210707_02_T1_0.tif', 'LC08_L2SP_131027_20210830_20210909_02_T1_0.tif', 'LC08_L2SP_131027_20211017_20211026_02_T1_0.tif', 'LC08_L2SP_131027_20211204_20211209_02_T1_0.tif', 'LC08_L2SP_131027_20211220_20211229_02_T1_0.tif', 'LC08_L2SP_131027_20220105_20220113_02_T1_0.tif', 'LC08_L2SP_131027_20220121_20220128_02_T1_0.tif', 'LC08_L2SP_131027_20220206_20220212_02_T1_0.tif', 'LC08_L2SP_131027_20220222_20220301_02_T1_0.tif', 'LC09_L2SP_131027_20211212_20220120_02_T1_0.tif', 'LC09_L2SP_131027_20211228_20220121_02_T1_0.tif', 'LC09_L2SP_131027_20220113_20220122_02_T1_0.tif', 'LC09_L2SP_131027_20220214_20220216_02_T1_0.tif']\n",
      "(400176, 64)\n",
      "[0 1 2 3 4 5 6]\n",
      "(400176, 64)\n",
      "Training ...\n",
      "Epoch 1/5\n",
      "400176/400176 [==============================] - 11s 26us/step - loss: 1.3523 - accuracy: 0.4992\n",
      "Epoch 2/5\n",
      "400176/400176 [==============================] - 10s 24us/step - loss: 0.8040 - accuracy: 0.6927\n",
      "Epoch 3/5\n",
      "400176/400176 [==============================] - 10s 24us/step - loss: 0.6402 - accuracy: 0.7490\n",
      "Epoch 4/5\n",
      "400176/400176 [==============================] - 10s 24us/step - loss: 0.5440 - accuracy: 0.7918\n",
      "Epoch 5/5\n",
      "400176/400176 [==============================] - 10s 24us/step - loss: 0.4611 - accuracy: 0.8351\n",
      "400176/400176 [==============================] - 63s 157us/step\n",
      "\n",
      "accuracy: 83.79%\n"
     ]
    }
   ],
   "source": [
    "# dir_img = r\"E:\\WORK\\Mongodia\\ThuDo_monggo\\Data_training\\Img_same_size\"\n",
    "# fp_mask = r\"E:\\WORK\\Mongodia\\ThuDo_monggo\\label_mask\\label_mask_nobuildup.tif\"\n",
    "# list_number_band = [1,2,3,4,5,6,7]\n",
    "# out_fp_csv_train = r\"E:\\WORK\\Mongodia\\Data_cut_img\\train.csv\"\n",
    "# fp_model_save = r\"E:\\WORK\\Mongodia\\Data_cut_img\\modelDense.h5\"\n",
    "\n",
    "dir_img = r\"E:\\WORK\\Mongodia\\ThuDo_monggo\\Data_training\\Img_same_size\"\n",
    "fp_mask = r\"E:\\WORK\\Mongodia\\ThuDo_monggo\\label_mask\\label_mask_nobuildup.tif\"\n",
    "list_number_band = [1,2,3,4,5,6,7]\n",
    "out_fp_csv_train = r\"E:\\WORK\\Mongodia\\Data_cut_img\\train_1111.csv\"\n",
    "fp_model_save = r\"E:\\WORK\\Mongodia\\Data_cut_img\\modelDense_111.h5\"\n",
    "\n",
    "\n",
    "list_name_file_sort = get_list_image_by_time(dir_img)\n",
    "list_fp_img = glob.glob(os.path.join(dir_img, \"*.tif\"))\n",
    "\n",
    "mask_train, index_nodata = get_index_and_mask_train(fp_mask, nodata_value=0)\n",
    "if not os.path.exists(out_fp_csv_train):\n",
    "    create_csv_train(list_fp_img, list_name_file_sort, list_number_band, index_nodata,out_fp_csv_train)\n",
    "\n",
    "df = make_time_seris(out_fp_csv_train)\n",
    "mask_train = np.tile(mask_train, 9) - 1\n",
    "print(np.unique(mask_train))\n",
    "df['label'] = mask_train\n",
    "df = df.reset_index()\n",
    "\n",
    "X_train, Y_train = create_data_train(df)\n",
    "print('Training ...')\n",
    "train(X_train, Y_train, classes=7, epochs=1000, batch_size=1000, shuffle=True, model_path=fp_model_save)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc63a6eef95843afe201fce49e80730796a68a524bff5092aa076c4c583efa68"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
