{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os, glob\n",
    "import rasterio\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rasterio.windows import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_window(df_data, model):\n",
    "    df_data = xgb.DMatrix(df_data)\n",
    "    X_predict = model.predict(df_data)\n",
    "    return X_predict.astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_to_input_model(array, list_number_band):\n",
    "    i = 0\n",
    "    dfObj = pd.DataFrame()\n",
    "    for band in array:\n",
    "        band = band.flatten()\n",
    "        name_band = f\"band {list_number_band[i]}\"\n",
    "        dfObj[name_band] = band\n",
    "        i+=1\n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_window(array_window, model, list_number_band):\n",
    "    shape_predict = array_window.shape[1:]\n",
    "    df_window = convert_img_to_input_model(array_window, list_number_band)\n",
    "    x_predict = predict_window(df_window, model)\n",
    "    return np.array([x_predict.reshape(shape_predict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_window_many_chanel(output_ds, arr_c, s_h, e_h ,s_w, e_w, sw_w, sw_h, size_w_crop, size_h_crop):\n",
    "    for c, arr in enumerate(arr_c):\n",
    "        output_ds.write(arr[s_h:e_h,s_w:e_w],window = Window(sw_w, sw_h, size_w_crop, size_h_crop), indexes= c + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_big(out_fp_predict, fp_img_large, input_size, crop_size, model, list_number_band):\n",
    "    with rasterio.open(fp_img_large) as src:\n",
    "        h,w = src.height,src.width\n",
    "        source_crs = src.crs\n",
    "        source_transform = src.transform\n",
    "        dtype_or = src.dtypes\n",
    "        num_band = src.count\n",
    "        \n",
    "    with rasterio.open(out_fp_predict, 'w', driver='GTiff',\n",
    "                                height = h, width = w,\n",
    "                                count=1, dtype=dtype_or[0],\n",
    "                                crs=source_crs,\n",
    "                                transform=source_transform,\n",
    "                                nodata=0,\n",
    "                                compress='lzw') as output_ds:\n",
    "        output_ds = np.empty((1,h,w))\n",
    "        \n",
    "        \n",
    "        \n",
    "    padding = int((input_size - crop_size)/2)\n",
    "    list_weight = list(range(0, w, crop_size))\n",
    "    list_hight = list(range(0, h, crop_size))\n",
    "\n",
    "\n",
    "    src = rasterio.open(fp_img_large)\n",
    "\n",
    "    with rasterio.open(out_fp_predict,\"r+\") as output_ds:\n",
    "        with tqdm(total=len(list_hight)*len(list_weight)) as pbar:\n",
    "            for start_h_org in list_hight:\n",
    "                for start_w_org in list_weight:\n",
    "                    # print('join')\n",
    "                    # vi tri bat dau\n",
    "                    h_crop_start = start_h_org - padding\n",
    "                    w_crop_start = start_w_org - padding\n",
    "                    # kich thuoc\n",
    "                    tmp_img_size_model = np.zeros((num_band, input_size,input_size))\n",
    "                    # truong hop 0 0\n",
    "                    if h_crop_start < 0 and w_crop_start < 0:\n",
    "                        # continue\n",
    "                        h_crop_start = 0\n",
    "                        w_crop_start = 0\n",
    "                        size_h_crop = crop_size + padding\n",
    "                        size_w_crop = crop_size + padding\n",
    "                        img_window_crop  = src.read(window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "                        tmp_img_size_model[:, padding:, padding:] = img_window_crop\n",
    "                        img_predict = predict_one_window(tmp_img_size_model, model, list_number_band) + 1\n",
    "                        write_window_many_chanel(output_ds, img_predict, padding, crop_size + padding, padding, crop_size + padding, \n",
    "                                                                        start_w_org, start_h_org, crop_size, crop_size)\n",
    "                    \n",
    "                    # truong hop h = 0 va w != 0\n",
    "                    elif h_crop_start < 0:\n",
    "                        h_crop_start = 0\n",
    "                        size_h_crop = crop_size + padding\n",
    "                        size_w_crop = min(crop_size + 2*padding, w - start_w_org + padding)\n",
    "                        img_window_crop  = src.read(window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "                        \n",
    "                        if size_w_crop == w - start_w_org + padding:\n",
    "                            end_c_index_w =  size_w_crop\n",
    "                            tmp_img_size_model[:,padding:,:end_c_index_w] = img_window_crop\n",
    "                        else:\n",
    "                            end_c_index_w = crop_size + padding\n",
    "                            tmp_img_size_model[:, padding:,:] = img_window_crop\n",
    "                        img_predict = predict_one_window(tmp_img_size_model, model, list_number_band) + 1\n",
    "                        write_window_many_chanel(output_ds, img_predict, padding, crop_size + padding ,padding, end_c_index_w, \n",
    "                                                    start_w_org, start_h_org,  min(crop_size, w - start_w_org), crop_size)\n",
    "                    \n",
    "                    # Truong hop w = 0, h!=0 \n",
    "                    elif w_crop_start < 0:\n",
    "                        w_crop_start = 0\n",
    "                        size_w_crop = crop_size + padding\n",
    "                        size_h_crop = min(crop_size + 2*padding, h - start_h_org + padding)\n",
    "                        img_window_crop  = src.read(window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "                        \n",
    "                        if size_h_crop == h - start_h_org + padding:\n",
    "                            end_c_index_h =  size_h_crop\n",
    "                            tmp_img_size_model[:,:end_c_index_h,padding:] = img_window_crop\n",
    "                        else:\n",
    "                            end_c_index_h = crop_size + padding\n",
    "                            tmp_img_size_model[:,:, padding:] = img_window_crop\n",
    "                        img_predict = predict_one_window(tmp_img_size_model, model, list_number_band) + 1\n",
    "                        write_window_many_chanel(output_ds, img_predict, padding, end_c_index_h, padding, crop_size + padding, \n",
    "                                                    start_w_org, start_h_org, crop_size, min(crop_size, h - start_h_org))\n",
    "                        \n",
    "                    # Truong hop ca 2 deu khac khong\n",
    "                    else:\n",
    "                        size_w_crop = min(crop_size +2*padding, w - start_w_org + padding)\n",
    "                        size_h_crop = min(crop_size +2*padding, h - start_h_org + padding)\n",
    "                        img_window_crop  = src.read(window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "                        # print(img_window_crop.shape, size_w_crop, size_h_crop)\n",
    "                        if size_w_crop < (crop_size + 2*padding) and size_h_crop < (crop_size + 2*padding):\n",
    "                            print(img_window_crop.shape, size_w_crop, size_h_crop)\n",
    "                            end_c_index_h = size_h_crop\n",
    "                            end_c_index_w = size_w_crop\n",
    "                            tmp_img_size_model[:,:end_c_index_h,:   end_c_index_w] = img_window_crop\n",
    "                        elif size_w_crop < (crop_size + 2*padding):\n",
    "                            end_c_index_h = crop_size + padding\n",
    "                            end_c_index_w = size_w_crop\n",
    "                            tmp_img_size_model[:,:,:end_c_index_w] = img_window_crop\n",
    "                        elif size_h_crop < (crop_size + 2*padding):\n",
    "                            end_c_index_w = crop_size + padding\n",
    "                            end_c_index_h = size_h_crop\n",
    "                            tmp_img_size_model[:,:end_c_index_h,:] = img_window_crop\n",
    "                        else:\n",
    "                            end_c_index_w = crop_size + padding\n",
    "                            end_c_index_h = crop_size + padding\n",
    "                            tmp_img_size_model[:,:,:] = img_window_crop\n",
    "                        img_predict = predict_one_window(tmp_img_size_model, model, list_number_band) + 1 \n",
    "                        write_window_many_chanel(output_ds, img_predict, padding, end_c_index_h, padding, end_c_index_w, \n",
    "                                                    start_w_org, start_h_org, min(crop_size, w - start_w_org), min(crop_size, h - start_h_org))\n",
    "                    pbar.update()\n",
    "        output_ds.write_colormap(\n",
    "                    1, {\n",
    "                        1: (255, 0, 0, 255),\n",
    "                        2: (255,255,0, 255),\n",
    "                        3:(128,0,0,255),\n",
    "                        4:(0,255,0,255),\n",
    "                        5:(0,128,0,255),\n",
    "                        6:(0,0,255,255) })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Mongolia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\WORK\\Mongodia\\Data\\Imgpredict_xgboostmodel_5000_v2_num_round_100_max_depth7_7Band\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 80/81 [01:46<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 861, 751) 751 861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:47<00:00,  1.33s/it]\n",
      " 99%|█████████▉| 80/81 [01:49<00:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 861, 751) 751 861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:50<00:00,  1.37s/it]\n",
      " 99%|█████████▉| 80/81 [01:49<00:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 861, 751) 751 861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:50<00:00,  1.36s/it]\n",
      " 99%|█████████▉| 80/81 [01:54<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 861, 761) 761 861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:55<00:00,  1.42s/it]\n",
      " 99%|█████████▉| 80/81 [01:53<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 871, 761) 761 871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:54<00:00,  1.42s/it]\n",
      " 99%|█████████▉| 80/81 [01:50<00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 871, 761) 761 871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:52<00:00,  1.38s/it]\n",
      " 99%|█████████▉| 80/81 [01:46<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 861, 761) 761 861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:47<00:00,  1.33s/it]\n",
      " 99%|█████████▉| 80/81 [01:46<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 861, 751) 751 861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:48<00:00,  1.33s/it]\n",
      " 99%|█████████▉| 80/81 [01:46<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 821, 661) 661 821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:47<00:00,  1.32s/it]\n",
      " 99%|█████████▉| 80/81 [01:46<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 851, 751) 751 851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:47<00:00,  1.33s/it]\n",
      " 99%|█████████▉| 80/81 [01:45<00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 851, 761) 761 851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:46<00:00,  1.32s/it]\n",
      " 99%|█████████▉| 80/81 [01:46<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 851, 761) 761 851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:47<00:00,  1.33s/it]\n",
      " 99%|█████████▉| 80/81 [01:46<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 851, 761) 761 851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:47<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "in_img_dir = r\"E:\\WORK\\Mongodia\\Data\\Img\"\n",
    "model_path = r\"E:\\WORK\\Mongodia\\pixel_base\\model_5000_v2_num_round_100_max_depth7_7Band.model\"\n",
    "\n",
    "out_dir_predict = os.path.join(in_img_dir + 'predict_xgboost' + os.path.basename(model_path)[:-6])\n",
    "if not os.path.exists(out_dir_predict):\n",
    "    os.makedirs(out_dir_predict)\n",
    "print(out_dir_predict)\n",
    "\n",
    "crop_size = 900\n",
    "input_size = 1000\n",
    "list_number_band = [1,2,3,4,5,6,7]\n",
    "\n",
    "model = xgb.Booster({'nthread': 20})\n",
    "model.load_model(model_path)\n",
    "\n",
    "list_fp_img = glob.glob(os.path.join(in_img_dir, '*.tif'))\n",
    "for fp_img_large in list_fp_img:\n",
    "    out_fp_predict = os.path.join(out_dir_predict, os.path.basename(fp_img_large))\n",
    "    predict_big(out_fp_predict, fp_img_large, input_size, crop_size, model, list_number_band)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc63a6eef95843afe201fce49e80730796a68a524bff5092aa076c4c583efa68"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
