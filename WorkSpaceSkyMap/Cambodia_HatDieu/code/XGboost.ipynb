{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  7 16:15:55 2022\n",
    "\n",
    "@author: SkyMap\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "    \n",
    "import rasterio\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_and_mask_train(fp_mask, nodata_value=0):\n",
    "    src = rasterio.open(fp_mask)\n",
    "    mask = src.read()[0].flatten()\n",
    "    index_nodata = np.where(mask == nodata_value)\n",
    "    mask_train = np.delete(mask, index_nodata)\n",
    "    return mask_train, index_nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_flatten_train(fp_img, list_number_band, index_nodata):\n",
    "    src = rasterio.open(fp_img)\n",
    "    # return to img train\n",
    "    list_band_have = list(range(1,src.count+1))\n",
    "    dfObj = pd.DataFrame()\n",
    "    if set(list_number_band).issubset(list_band_have):\n",
    "        img = src.read(list_number_band)\n",
    "        i = 0\n",
    "        for band in img:\n",
    "            band = band.flatten()\n",
    "            band = np.delete(band, index_nodata)\n",
    "            name_band = f\"band {list_number_band[i]}\"\n",
    "            dfObj[name_band] = band\n",
    "            i+=1\n",
    "        return dfObj\n",
    "    else:\n",
    "        miss = np.setdiff1d(list_number_band, list_band_have)\n",
    "        print(\"*\"*15, \"ERROR\", \"*\"*15)\n",
    "        print(f\"Image dont have band : {miss.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_train_from_ones_img(fp_img, fp_mask, list_band_to_train, size_get=None):\n",
    "    mask_train, index_nodata = get_index_and_mask_train(fp_mask)\n",
    "    df_dataset = get_df_flatten_train(fp_img, list_band_to_train, index_nodata)\n",
    "    df_dataset['label'] = mask_train - 1\n",
    "    print(np.unique(mask_train - 1),'zeeeeeeeee')\n",
    "\n",
    "\n",
    "    g = df_dataset.groupby('label', group_keys=False)\n",
    "    g = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "    g = pd.DataFrame(g)\n",
    "    # size_get = 3000       # sample size\n",
    "    if size_get:\n",
    "        replace = False  # with replacement\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size_get, replace),:]\n",
    "        a= g.groupby('label', as_index=False).apply(fn)\n",
    "        # print(a)\n",
    "        return pd.DataFrame(a)\n",
    "    else:\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_train_all_img(list_fp_img, list_fp_mask, list_band_to_train, out_fp_csv_train, size_get=None):\n",
    "    print(list_fp_img)\n",
    "    dir_name_img = os.path.dirname(list_fp_img[0])\n",
    "    # list_df_all = []\n",
    "    for fp_mask in list_fp_mask:\n",
    "        base_name = os.path.basename(fp_mask)\n",
    "        fp_img = os.path.join(dir_name_img, base_name)\n",
    "        df_tmp = create_data_train_from_ones_img(fp_img, fp_mask, list_band_to_train, size_get)\n",
    "        # print(df_tmp)\n",
    "        # list_df_all.append(df_tmp)\n",
    "        # result = pd.concat(list_df_all)\n",
    "        df_tmp.to_csv(out_fp_csv_train, mode='a', index=False, header=False)\n",
    "        print('done ', base_name)\n",
    "        # print(result)\n",
    "    # print(np.unique(result['label'].to_numpy()))\n",
    "    # result.to_csv(out_fp_csv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_train(csv_training):\n",
    "    datasets = pd.read_csv(csv_training).iloc[:, 2:]\n",
    "    print(datasets.shape)\n",
    "    X = datasets.iloc[:, :-1]\n",
    "    Y = datasets.iloc[:, -1]\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(Y)\n",
    "    encoded_Y = encoder.transform(Y)\n",
    "    Y = np_utils.to_categorical(encoded_Y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_train_Xgboost(csv_training, training_per = 0.8):\n",
    "    datasets = pd.read_csv(csv_training)#.iloc[:, 2:]\n",
    "    ds_train = datasets.sample(frac=training_per)\n",
    "    ds_test = datasets[~datasets.isin(ds_train)].dropna()\n",
    "\n",
    "    X_train = ds_train.iloc[:, :-1]\n",
    "    Y_train = ds_train.iloc[:, -1]\n",
    "    X_test = ds_test.iloc[:, :-1]\n",
    "    Y_test = ds_test.iloc[:, -1]\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\WORK\\\\Mongodia\\\\pixel_base\\\\img\\\\LC08_L2SP_133026_20210609_20210615_02_T1_0.tif', 'E:\\\\WORK\\\\Mongodia\\\\pixel_base\\\\img\\\\LC08_L2SP_133026_20210913_20210924_02_T1_0.tif']\n",
      "[0 1 2 3 4 5] zeeeeeeeee\n",
      "done  LC08_L2SP_133026_20210609_20210615_02_T1_0.tif\n",
      "[0 1 2 3 4 5] zeeeeeeeee\n",
      "done  LC08_L2SP_133026_20210913_20210924_02_T1_0.tif\n",
      "Training ...\n",
      "[0]\teval-auc:0.98988\ttrain-auc:0.99353\n",
      "[1]\teval-auc:0.99544\ttrain-auc:0.99831\n",
      "[2]\teval-auc:0.99723\ttrain-auc:0.99929\n",
      "[3]\teval-auc:0.99791\ttrain-auc:0.99968\n",
      "[4]\teval-auc:0.99845\ttrain-auc:0.99985\n",
      "[5]\teval-auc:0.99856\ttrain-auc:0.99993\n",
      "[6]\teval-auc:0.99870\ttrain-auc:0.99996\n",
      "[7]\teval-auc:0.99885\ttrain-auc:0.99998\n",
      "[8]\teval-auc:0.99889\ttrain-auc:0.99999\n",
      "[9]\teval-auc:0.99894\ttrain-auc:1.00000\n",
      "[10]\teval-auc:0.99893\ttrain-auc:1.00000\n",
      "[11]\teval-auc:0.99895\ttrain-auc:1.00000\n",
      "[12]\teval-auc:0.99901\ttrain-auc:1.00000\n",
      "[13]\teval-auc:0.99903\ttrain-auc:1.00000\n",
      "[14]\teval-auc:0.99908\ttrain-auc:1.00000\n",
      "[15]\teval-auc:0.99910\ttrain-auc:1.00000\n",
      "[16]\teval-auc:0.99909\ttrain-auc:1.00000\n",
      "[17]\teval-auc:0.99913\ttrain-auc:1.00000\n",
      "[18]\teval-auc:0.99915\ttrain-auc:1.00000\n",
      "[19]\teval-auc:0.99915\ttrain-auc:1.00000\n",
      "[20]\teval-auc:0.99915\ttrain-auc:1.00000\n",
      "[21]\teval-auc:0.99915\ttrain-auc:1.00000\n",
      "[22]\teval-auc:0.99916\ttrain-auc:1.00000\n",
      "[23]\teval-auc:0.99917\ttrain-auc:1.00000\n",
      "[24]\teval-auc:0.99918\ttrain-auc:1.00000\n",
      "[25]\teval-auc:0.99919\ttrain-auc:1.00000\n",
      "[26]\teval-auc:0.99921\ttrain-auc:1.00000\n",
      "[27]\teval-auc:0.99922\ttrain-auc:1.00000\n",
      "[28]\teval-auc:0.99924\ttrain-auc:1.00000\n",
      "[29]\teval-auc:0.99924\ttrain-auc:1.00000\n",
      "[30]\teval-auc:0.99925\ttrain-auc:1.00000\n",
      "[31]\teval-auc:0.99927\ttrain-auc:1.00000\n",
      "[32]\teval-auc:0.99927\ttrain-auc:1.00000\n",
      "[33]\teval-auc:0.99930\ttrain-auc:1.00000\n",
      "[34]\teval-auc:0.99930\ttrain-auc:1.00000\n",
      "[35]\teval-auc:0.99930\ttrain-auc:1.00000\n",
      "[36]\teval-auc:0.99931\ttrain-auc:1.00000\n",
      "[37]\teval-auc:0.99930\ttrain-auc:1.00000\n",
      "[38]\teval-auc:0.99931\ttrain-auc:1.00000\n",
      "[39]\teval-auc:0.99931\ttrain-auc:1.00000\n",
      "[40]\teval-auc:0.99931\ttrain-auc:1.00000\n",
      "[41]\teval-auc:0.99932\ttrain-auc:1.00000\n",
      "[42]\teval-auc:0.99932\ttrain-auc:1.00000\n",
      "[43]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[44]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[45]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[46]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[47]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[48]\teval-auc:0.99932\ttrain-auc:1.00000\n",
      "[49]\teval-auc:0.99932\ttrain-auc:1.00000\n",
      "[50]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[51]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[52]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[53]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[54]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[55]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[56]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[57]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[58]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[59]\teval-auc:0.99933\ttrain-auc:1.00000\n",
      "[60]\teval-auc:0.99934\ttrain-auc:1.00000\n",
      "[61]\teval-auc:0.99934\ttrain-auc:1.00000\n",
      "[62]\teval-auc:0.99934\ttrain-auc:1.00000\n",
      "[63]\teval-auc:0.99934\ttrain-auc:1.00000\n",
      "[64]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[65]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[66]\teval-auc:0.99936\ttrain-auc:1.00000\n",
      "[67]\teval-auc:0.99936\ttrain-auc:1.00000\n",
      "[68]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[69]\teval-auc:0.99936\ttrain-auc:1.00000\n",
      "[70]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[71]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[72]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[73]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[74]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[75]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[76]\teval-auc:0.99934\ttrain-auc:1.00000\n",
      "[77]\teval-auc:0.99934\ttrain-auc:1.00000\n",
      "[78]\teval-auc:0.99934\ttrain-auc:1.00000\n",
      "[79]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[80]\teval-auc:0.99934\ttrain-auc:1.00000\n",
      "[81]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[82]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[83]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[84]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[85]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[86]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[87]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[88]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[89]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[90]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[91]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[92]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[93]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[94]\teval-auc:0.99936\ttrain-auc:1.00000\n",
      "[95]\teval-auc:0.99935\ttrain-auc:1.00000\n",
      "[96]\teval-auc:0.99936\ttrain-auc:1.00000\n",
      "[97]\teval-auc:0.99936\ttrain-auc:1.00000\n",
      "[98]\teval-auc:0.99936\ttrain-auc:1.00000\n",
      "[99]\teval-auc:0.99936\ttrain-auc:1.00000\n"
     ]
    }
   ],
   "source": [
    "list_fp_img = glob.glob(r'E:\\WORK\\Mongodia\\pixel_base\\img\\*.tif')\n",
    "list_fp_mask = glob.glob(r'E:\\WORK\\Mongodia\\pixel_base\\mask\\*.tif')\n",
    "list_band_to_train = [1,2,3,4,5,6,7]\n",
    "out_fp_csv_train = r'E:\\WORK\\Mongodia\\pixel_base\\training.csv'\n",
    "fp_model_save = r\"E:\\WORK\\Mongodia\\pixel_base\\model_5000_v2_num_round_100_max_depth7_7Band.model\"\n",
    "if not os.path.exists(out_fp_csv_train):\n",
    "    create_data_train_all_img(list_fp_img, list_fp_mask, list_band_to_train, out_fp_csv_train)\n",
    "X_train, Y_train, X_test, Y_test = create_data_train_Xgboost(out_fp_csv_train, training_per = 0.8)\n",
    "print('Training ...')\n",
    "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=Y_test)\n",
    "num_round = 100\n",
    "param = {'max_depth': 7, 'eta': 1, 'objective': 'multi:softmax'}\n",
    "param['nthread'] = 5\n",
    "param['eval_metric'] = 'auc'\n",
    "param['num_class'] = 6\n",
    "param['gpu_id'] = 0\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "bst.save_model(fp_model_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10655, 7)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc63a6eef95843afe201fce49e80730796a68a524bff5092aa076c4c583efa68"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
