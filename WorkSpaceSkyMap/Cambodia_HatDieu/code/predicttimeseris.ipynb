{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  7 16:15:55 2022\n",
    "\n",
    "@author: SkyMap\n",
    "\"\"\"\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "import xgboost as xgb\n",
    "from scipy.ndimage import convolve\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_window_many_chanel(output_ds, arr_c, s_h, e_h ,s_w, e_w, sw_w, sw_h, size_w_crop, size_h_crop):\n",
    "    for c, arr in enumerate(arr_c):\n",
    "        output_ds.write(arr[s_h:e_h,s_w:e_w],window = Window(sw_w, sw_h, size_w_crop, size_h_crop), indexes= c + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_image_by_time(dir_img):\n",
    "    list_name_file = os.listdir(dir_img)\n",
    "    print(list_name_file)\n",
    "    list_time = []\n",
    "    for name in list_name_file:\n",
    "        list_time.append(name[17:25])\n",
    "    list_time.sort(key=lambda date: datetime.strptime(date, '%Y%m%d'))\n",
    "    return list_time[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_flatten_predict(img_window, list_number_band, name_atrr):\n",
    "    dfObj = pd.DataFrame()\n",
    "    i = 0\n",
    "    for band in img_window:\n",
    "        band = band.flatten()\n",
    "        name_band = f\"band {list_number_band[i]}_{name_atrr}\"\n",
    "        dfObj[name_band] = band\n",
    "        i+=1\n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_window(list_fp_img_large, list_name_file_sort, list_number_band, w_crop_start, h_crop_start, size_w_crop, size_h_crop):\n",
    "    fp_large_first = [s for s in list_fp_img_large if list_name_file_sort[0] in s][0]\n",
    "    with rasterio.open(fp_large_first) as src:\n",
    "            img_window = src.read(window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "    df_all_predict = get_df_flatten_predict(img_window, list_number_band, list_name_file_sort[0])\n",
    "\n",
    "    for name_file_sort in list_name_file_sort[1:]:\n",
    "        fp_large = [s for s in list_fp_img_large if name_file_sort in s][0]\n",
    "        with rasterio.open(fp_large) as src:\n",
    "            img_window = src.read(window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "        df_one_img = get_df_flatten_predict(img_window, list_number_band, name_file_sort)\n",
    "        df_all_predict = pd.concat([df_all_predict, df_one_img], axis=1)\n",
    "    return df_all_predict, img_window.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(df_all_predict, model, crop_size, shape_win):\n",
    "    para = 4\n",
    "    predictions = model.predict(df_all_predict, batch_size=1000, verbose=1)\n",
    "    predictions = np.transpose(predictions)\n",
    "    predictions = np.reshape(predictions, (-1, shape_win[0], shape_win[1]))\n",
    "    # print(predictions)\n",
    "    print('shape of predictions', predictions.shape)\n",
    "    # kernel = [[1, 1, 1, 1, 1],\n",
    "    #             [1, 1, 1, 1, 1],\n",
    "    #             [1, 1, para, 1, 1],\n",
    "    #             [1, 1, 1, 1, 1],\n",
    "    #             [1, 1, 1, 1, 1]]\n",
    "\n",
    "    # kernel = [[1, 1, 1],\n",
    "    #         [1, para, 1],\n",
    "    #         [1, 1, 1] ]\n",
    "    # kernel = [1]\n",
    "    # for i in range(len(predictions)):\n",
    "    #     predictions[i] = convolve(predictions[i], kernel, mode='constant', cval=0.0)\n",
    "    return np.array([np.argmax(predictions, axis=0).astype('uint16')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_big(out_fp_predict, fp_img_large, input_size, crop_size, model, list_number_band):\n",
    "def predict_big(out_fp_predict, list_fp_img_large, list_name_file_sort, list_number_band, crop_size, model):\n",
    "    fp_large_first = [s for s in list_fp_img_large if list_name_file_sort[0] in s][0]\n",
    "    with rasterio.open(fp_large_first) as src:\n",
    "        h,w = src.height,src.width\n",
    "        source_crs = src.crs\n",
    "        source_transform = src.transform\n",
    "        dtype_or = src.dtypes\n",
    "        \n",
    "    with rasterio.open(out_fp_predict, 'w', driver='GTiff',\n",
    "                                height = h, width = w,\n",
    "                                count=1, dtype=dtype_or[0],\n",
    "                                crs=source_crs,\n",
    "                                transform=source_transform,\n",
    "                                nodata=0,\n",
    "                                compress='lzw') as output_ds:\n",
    "        output_ds = np.empty((1,h,w))\n",
    "        \n",
    "        \n",
    "    input_size = crop_size    \n",
    "    padding = int((input_size - crop_size)/2)\n",
    "    list_weight = list(range(0, w, crop_size))\n",
    "    list_hight = list(range(0, h, crop_size))\n",
    "\n",
    "    with rasterio.open(out_fp_predict,\"r+\") as output_ds:\n",
    "        with tqdm(total=len(list_hight)*len(list_weight)) as pbar:\n",
    "            for start_h_org in list_hight:\n",
    "                for start_w_org in list_weight:\n",
    "                    # print('join')\n",
    "                    # vi tri bat dau\n",
    "                    h_crop_start = start_h_org - padding\n",
    "                    w_crop_start = start_w_org - padding\n",
    "                    # kich thuoc\n",
    "                    \n",
    "                    # truong hop 0 0\n",
    "                    if h_crop_start < 0 and w_crop_start < 0:\n",
    "                        # continue\n",
    "                        h_crop_start = 0\n",
    "                        w_crop_start = 0\n",
    "                        size_h_crop = crop_size + padding\n",
    "                        size_w_crop = crop_size + padding\n",
    "                        \n",
    "                        df_all_predict, shape_win = create_df_from_window(list_fp_img_large, list_name_file_sort, list_number_band, w_crop_start, h_crop_start, size_w_crop, size_h_crop)\n",
    "                        img_predict = predict_df(df_all_predict, model, crop_size, shape_win) + 1\n",
    "                        write_window_many_chanel(output_ds, img_predict, padding, crop_size + padding, padding, crop_size + padding, \n",
    "                                                                        start_w_org, start_h_org, crop_size, crop_size)\n",
    "                    \n",
    "                    # truong hop h = 0 va w != 0\n",
    "                    elif h_crop_start < 0:\n",
    "                        h_crop_start = 0\n",
    "                        size_h_crop = crop_size + padding\n",
    "                        size_w_crop = min(crop_size + 2*padding, w - start_w_org + padding)\n",
    "                        if size_w_crop == w - start_w_org + padding:\n",
    "                            end_c_index_w =  size_w_crop\n",
    "                        else:\n",
    "                            end_c_index_w = crop_size + padding\n",
    "\n",
    "                        df_all_predict, shape_win = create_df_from_window(list_fp_img_large, list_name_file_sort, list_number_band, w_crop_start, h_crop_start, size_w_crop, size_h_crop)\n",
    "                        img_predict = predict_df(df_all_predict, model, crop_size, shape_win) + 1\n",
    "                        write_window_many_chanel(output_ds, img_predict, padding, crop_size + padding ,padding, end_c_index_w, \n",
    "                                                    start_w_org, start_h_org,  min(crop_size, w - start_w_org), crop_size)\n",
    "                    \n",
    "                    # Truong hop w = 0, h!=0 \n",
    "                    elif w_crop_start < 0:\n",
    "                        w_crop_start = 0\n",
    "                        size_w_crop = crop_size + padding\n",
    "                        size_h_crop = min(crop_size + 2*padding, h - start_h_org + padding)\n",
    "                        \n",
    "                        if size_h_crop == h - start_h_org + padding:\n",
    "                            end_c_index_h =  size_h_crop\n",
    "                        else:\n",
    "                            end_c_index_h = crop_size + padding\n",
    "\n",
    "                        df_all_predict, shape_win = create_df_from_window(list_fp_img_large, list_name_file_sort, list_number_band, w_crop_start, h_crop_start, size_w_crop, size_h_crop)\n",
    "                        img_predict = predict_df(df_all_predict, model, crop_size, shape_win) + 1\n",
    "                        write_window_many_chanel(output_ds, img_predict, padding, end_c_index_h, padding, crop_size + padding, \n",
    "                                                    start_w_org, start_h_org, crop_size, min(crop_size, h - start_h_org))\n",
    "                        \n",
    "                    # Truong hop ca 2 deu khac khong\n",
    "                    else:\n",
    "                        size_w_crop = min(crop_size +2*padding, w - start_w_org + padding)\n",
    "                        size_h_crop = min(crop_size +2*padding, h - start_h_org + padding)\n",
    "                        # img_window_crop  = src.read(window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "                        # print(img_window_crop.shape, size_w_crop, size_h_crop)\n",
    "                        if size_w_crop < (crop_size + 2*padding) and size_h_crop < (crop_size + 2*padding):\n",
    "                            # print(img_window_crop.shape, size_w_crop, size_h_crop)\n",
    "                            end_c_index_h = size_h_crop\n",
    "                            end_c_index_w = size_w_crop\n",
    "                            \n",
    "                        elif size_w_crop < (crop_size + 2*padding):\n",
    "                            end_c_index_h = crop_size + padding\n",
    "                            end_c_index_w = size_w_crop\n",
    "                            \n",
    "                        elif size_h_crop < (crop_size + 2*padding):\n",
    "                            end_c_index_w = crop_size + padding\n",
    "                            end_c_index_h = size_h_crop\n",
    "                            \n",
    "                        else:\n",
    "                            end_c_index_w = crop_size + padding\n",
    "                            end_c_index_h = crop_size + padding\n",
    "                            \n",
    "                        df_all_predict, shape_win = create_df_from_window(list_fp_img_large, list_name_file_sort, list_number_band, w_crop_start, h_crop_start, size_w_crop, size_h_crop)\n",
    "                        img_predict = predict_df(df_all_predict, model, crop_size, shape_win) + 1 \n",
    "                        write_window_many_chanel(output_ds, img_predict, padding, end_c_index_h, padding, end_c_index_w, \n",
    "                                                    start_w_org, start_h_org, min(crop_size, w - start_w_org), min(crop_size, h - start_h_org))\n",
    "                    pbar.update()\n",
    "        output_ds.write_colormap(\n",
    "                    1, {\n",
    "                        1: (255, 0, 0, 255),\n",
    "                        2: (255,255,0, 255),\n",
    "                        3:(128,0,0,255),\n",
    "                        4:(0,255,0,255),\n",
    "                        5:(0,128,0,255),\n",
    "                        6:(0,0,255,255) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LC08_L2SP_133026_20210201_20210302_02_T1_0.tif', 'LC08_L2SP_133026_20210305_20210312_02_T1_0.tif', 'LC08_L2SP_133026_20210406_20210415_02_T1_0.tif', 'LC08_L2SP_133026_20210609_20210615_02_T1_0.tif', 'LC08_L2SP_133026_20210913_20210924_02_T1_0.tif', 'LC08_L2SP_133026_20211031_20211109_02_T1_0.tif', 'LC08_L2SP_133026_20220119_20220127_02_T1_0.tif', 'LC08_L2SP_133026_20220204_20220212_02_T1_0.tif', 'LC09_L2SP_133026_20211121_20220120_02_T1_0.tif', 'LC09_L2SP_133026_20211226_20220121_02_T1_0.tif', 'LC09_L2SP_133026_20220127_20220129_02_T1_0.tif', 'LC09_L2SP_133026_20220212_20220214_02_T1_0.tif', 'LC09_L2SP_133026_20220228_20220302_02_T1_0.tif']\n",
      "['20210201', '20210305', '20210406', '20210609', '20210913', '20211031', '20211121', '20211226', '20220119']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000/1000000 [==============================] - 5s 5us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:07<01:26,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 1000, 1000)\n",
      "1000000/1000000 [==============================] - 4s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:14<01:14,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 1000, 1000)\n",
      "1000000/1000000 [==============================] - 4s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:22<01:05,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 1000, 1000)\n",
      "132000/132000 [==============================] - 1s 5us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:23<00:40,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 1000, 132)\n",
      "1000000/1000000 [==============================] - 4s 4us/step\n",
      "shape of predictions (6, 1000, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:30<00:40,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000/1000000 [==============================] - 4s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:38<00:37,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 1000, 1000)\n",
      "1000000/1000000 [==============================] - 4s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:45<00:33,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 1000, 1000)\n",
      "132000/132000 [==============================] - 1s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [00:46<00:20,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 1000, 132)\n",
      "540000/540000 [==============================] - 2s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:51<00:14,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 540, 1000)\n",
      "540000/540000 [==============================] - 2s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [00:55<00:08,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 540, 1000)\n",
      "540000/540000 [==============================] - ETA:  - 2s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:58<00:04,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 540, 1000)\n",
      "71280/71280 [==============================] - 0s 4us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:59<00:00,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (6, 540, 132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "out_fp_predict = r\"E:\\WORK\\Mongodia\\Data\\predict_time\\run_with_nokerel_cut_box.tif\"\n",
    "# dir_img = r\"E:\\WORK\\Mongodia\\Data\\Img\"\n",
    "# dir_img = r\"E:\\WORK\\Mongodia\\Data_cut_img\\Img\"\n",
    "dir_img =r\"E:\\WORK\\Mongodia\\Data\\Img_Cut_box\"\n",
    "list_number_band = [1,2,3,4,5,6,7]\n",
    "crop_size = 1000\n",
    "\n",
    "list_fp_img_large = glob.glob(os.path.join(dir_img, \"*.tif\"))\n",
    "list_name_file_sort = get_list_image_by_time(dir_img)\n",
    "print(list_name_file_sort)\n",
    "model_fp = r\"E:\\WORK\\Mongodia\\Data_cut_img\\modelDense.h5\"\n",
    "model = load_model(model_fp)\n",
    "predict_big(out_fp_predict, list_fp_img_large, list_name_file_sort, list_number_band, crop_size, model)\n",
    "print('done')\n",
    "# img = rasterio.open(r\"E:\\WORK\\Mongodia\\Data\\Img\\LC08_L2SP_133026_20210201_20210302_02_T1.tif\").read()\n",
    "# img = rasterio.open(r\"E:\\WORK\\Mongodia\\Data_cut_img\\Img\\LC08_L2SP_133026_20210201_20210302_02_T1_0.tif\").read()\n",
    "img = rasterio.open(r\"E:\\WORK\\Mongodia\\Data\\Img_Cut_box\\LC08_L2SP_133026_20210201_20210302_02_T1_0.tif\").read()\n",
    "a= np.array([np.sum(img, axis=0)])\n",
    "idx_nodata = np.where(a==0)\n",
    "\n",
    "with rasterio.open(out_fp_predict, \"r+\") as dst:\n",
    "    img = dst.read()\n",
    "    img[idx_nodata] = 0\n",
    "    dst.write(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc63a6eef95843afe201fce49e80730796a68a524bff5092aa076c4c583efa68"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
